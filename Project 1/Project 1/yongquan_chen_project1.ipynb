{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: CelebA Facial Attribute Recognition Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "cudnn.benchmark = True\n",
    "np.set_printoptions(edgeitems = 40, linewidth = 200)\n",
    "torch.set_printoptions(edgeitems = 40, linewidth = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "num_workers = 0\n",
    "batch_size = 32\n",
    "test_batch = 200\n",
    "\n",
    "# Optimizer\n",
    "lr = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0001\n",
    "\n",
    "# Model\n",
    "crop_size = 320\n",
    "arch = 'resnest50'\n",
    "\n",
    "# Focal Loss\n",
    "alpha = torch.tensor([\n",
    "  [0.75, 0.75],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.75, 0.75],\n",
    "  [0.25, 0.25],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.25, 0.25],\n",
    "  [0.75, 0.75],\n",
    "  [0.25, 0.25],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.25, 0.25],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.25, 0.25]]).cuda()\n",
    "alpha_lfwa = torch.tensor([\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.75, 0.75],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.75, 0.75],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.25, 0.25],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.75, 0.75],\n",
    "  [0.25, 0.25],\n",
    "  [0.75, 0.75]]).cuda()\n",
    "gamma = 2.0\n",
    "\n",
    "# Training\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Checkpoint (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_checkpoint = arch + '.checkpoint25.pth.tar'\n",
    "checkpoint = torch.load(resume_checkpoint)\n",
    "arch = checkpoint['arch']\n",
    "batch_size = checkpoint['batch_size']\n",
    "crop_size = checkpoint['crop_size']\n",
    "alpha = checkpoint['alpha']\n",
    "gamma = checkpoint['gamma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "def pil_loader(path):\n",
    "  # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "  with open(path, 'rb') as f:\n",
    "    img = Image.open(f)\n",
    "    return img.convert('RGB')\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\n",
    "       Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CelebA and LFW Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from https://github.com/d-li14/face-attribute-prediction/blob/master/celeba.py\n",
    "class CelebA(data.Dataset):\n",
    "  def __init__(self, root, ann_file, image_folder, transform=None, target_transform=None):\n",
    "    images = []\n",
    "    targets = []\n",
    "\n",
    "    for line in open(os.path.join(root, 'Anno', ann_file), 'r'):\n",
    "      sample = line.split()\n",
    "      if len(sample) != 41:\n",
    "        raise(RuntimeError(\"# Annotated face attributes of CelebA dataset should not be different from 40\"))\n",
    "      images.append(sample[0])\n",
    "      # targets.append([int(i) for i in sample[1:]])\n",
    "      targets.append([*map(lambda x: 0 if int(x) < 0 else int(x), sample[1:])])\n",
    "    self.images = [os.path.join(root, image_folder, img) for img in images]\n",
    "    self.targets = targets\n",
    "    self.transform = transform\n",
    "    self.target_transform = target_transform\n",
    "    self.loader = pil_loader\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    path = self.images[index]\n",
    "    sample = self.loader(path)\n",
    "    target = self.targets[index]\n",
    "    target = torch.LongTensor(target)\n",
    "    if self.transform is not None:\n",
    "      sample = self.transform(sample)\n",
    "    if self.target_transform is not None:\n",
    "      target = self.target_transform(target)\n",
    "    return sample, target\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.images)\n",
    "\n",
    "class LFWA(data.Dataset):\n",
    "  def __init__(self, root, ann_file, image_folder, transform=None):\n",
    "    images = []\n",
    "\n",
    "    for line in open(os.path.join(root, 'Anno', ann_file), 'r'):\n",
    "      sample = line.split()\n",
    "      images.append(sample[0])\n",
    "    self.images = [os.path.join(root, image_folder, img) for img in images]\n",
    "    self.transform = transform\n",
    "    self.loader = pil_loader\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    path = self.images[index]\n",
    "    sample = self.loader(path)\n",
    "    if self.transform is not None:\n",
    "      sample = self.transform(sample)\n",
    "    return sample, torch.empty(0)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "  def __init__(self, in_features, out_features):\n",
    "    super(Classifier, self).__init__()\n",
    "    for i in range(out_features):\n",
    "      setattr(self, 'classifier' + str(i).zfill(2), nn.Linear(in_features, 2))\n",
    "    self.num_attributes = out_features\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x.view(x.size(0), -1)\n",
    "    y = []\n",
    "    for i in range(self.num_attributes):\n",
    "      classifier = getattr(self, 'classifier' + str(i).zfill(2))\n",
    "      y.append(classifier(x))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "  def __init__(self, alpha, gamma = 2):\n",
    "    super(FocalLoss, self).__init__()\n",
    "    self.alpha = alpha\n",
    "    self.gamma = gamma\n",
    "\n",
    "  def forward(self, inputs, targets, j):\n",
    "    CE_loss = F.cross_entropy(inputs, targets, weight = self.alpha[j])\n",
    "    pt = torch.exp(-CE_loss)\n",
    "    F_loss = (1 - pt)**self.gamma * CE_loss\n",
    "    return F_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate, Prediction Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer):\n",
    "  model.train()\n",
    "  losses = [AverageMeter() for _ in range(40)]\n",
    "  top1 = [AverageMeter() for _ in range(40)]\n",
    "\n",
    "  print(\"Batch 1/%d\" % len(train_loader))\n",
    "  for i, (input, target) in enumerate(train_loader):\n",
    "    input = input.cuda(non_blocking = True)\n",
    "    target = target.cuda(non_blocking = True)\n",
    "\n",
    "    output = model(input)\n",
    "\n",
    "    loss = []\n",
    "    prec1 = []\n",
    "    for j in range(len(output)):\n",
    "      loss.append(criterion(output[j], target[:, j], j))\n",
    "      prec1.append(accuracy(output[j], target[:, j], topk = (1,)))\n",
    "\n",
    "      losses[j].update(loss[j].item(), input.size(0))\n",
    "      top1[j].update(prec1[j][0].item(), input.size(0))\n",
    "\n",
    "    losses_avg = [losses[k].avg for k in range(len(losses))]\n",
    "    top1_avg = [top1[k].avg for k in range(len(top1))]\n",
    "    loss_avg = sum(losses_avg) / len(losses_avg)\n",
    "    prec1_avg = sum(top1_avg) / len(top1_avg)\n",
    "    clear_output(wait = True)\n",
    "    print(\"Batch %d/%d\\nAverage Loss: %.10f\\nAverage Precision: %.10f\" % (i + 1, len(train_loader), loss_avg, prec1_avg))\n",
    "    print(\"Accuracy: %s\" % ['%.2f' % top1_avg_j for top1_avg_j in top1_avg])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss_sum = sum(loss)\n",
    "    loss_sum.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  return loss_avg, prec1_avg\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "  model.eval()\n",
    "  losses = [AverageMeter() for _ in range(40)]\n",
    "  top1 = [AverageMeter() for _ in range(40)]\n",
    "\n",
    "  with torch.no_grad():\n",
    "    print(\"Batch 1/%d\" % len(val_loader))\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "      input = input.cuda(non_blocking = True)\n",
    "      target = target.cuda(non_blocking = True)\n",
    "\n",
    "      output = model(input)\n",
    "\n",
    "      loss = []\n",
    "      prec1 = []\n",
    "      for j in range(len(output)):\n",
    "        loss.append(criterion(output[j], target[:, j], j))\n",
    "        prec1.append(accuracy(output[j], target[:, j], topk = (1,)))\n",
    "\n",
    "        losses[j].update(loss[j].item(), input.size(0))\n",
    "        top1[j].update(prec1[j][0].item(), input.size(0))\n",
    "\n",
    "      losses_avg = [losses[k].avg for k in range(len(losses))]\n",
    "      top1_avg = [top1[k].avg for k in range(len(top1))]\n",
    "      loss_avg = sum(losses_avg) / len(losses_avg)\n",
    "      prec1_avg = sum(top1_avg) / len(top1_avg)\n",
    "      clear_output(wait = True)\n",
    "      print(\"Batch %d/%d\\nAverage Loss: %.10f\\nAverage Accuracy: %.10f\" % (i + 1, len(val_loader), loss_avg, prec1_avg))\n",
    "      print(\"Accuracy: %s\" % ['%.2f' % top1_avg_j for top1_avg_j in top1_avg])\n",
    "\n",
    "  return loss_avg, prec1_avg\n",
    "\n",
    "def predict(eval_loader, model, eval_dataset):\n",
    "  model.eval()\n",
    "  pred = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    print(\"Batch 1/%d\" % len(eval_loader))\n",
    "    for i, (input, target) in enumerate(eval_loader):\n",
    "      input = input.cuda(non_blocking = True)\n",
    "\n",
    "      output = model(input)\n",
    "\n",
    "      pred_batch = []\n",
    "      for j in range(len(output)):\n",
    "        _, pred_j = output[j].topk(1,1,True,True)\n",
    "        pred_j[pred_j == 0] = -1\n",
    "        pred_batch.append(pred_j)\n",
    "      if i == 0:\n",
    "        pred = torch.cat(pred_batch, dim = 1).cpu().numpy().astype(np.int8)\n",
    "      else:\n",
    "        pred = np.append(pred, torch.cat(pred_batch, dim = 1).cpu().numpy().astype(np.int8), 0)\n",
    "      clear_output(wait = True)\n",
    "      print(\"Batch %d/%d\" % (i + 1, len(eval_loader)))\n",
    "\n",
    "  with open('predictions.txt', 'w') as outFile:\n",
    "    for i, row in enumerate(pred):\n",
    "      filename = os.path.basename(eval_dataset.images[i])\n",
    "      outFile.write(filename + ' ' + ' '.join(map(\"{:2d}\".format, pred[i])) + '\\n')\n",
    "  return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet mean and std\n",
    "normalize = transforms.Normalize(\n",
    "  mean = [0.485, 0.456, 0.406],\n",
    "  std = [0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "train_dataset = CelebA(\n",
    "  '',\n",
    "  'train_40_att_list.txt',\n",
    "  'Img',\n",
    "  transforms.Compose([\n",
    "    transforms.RandomResizedCrop(crop_size, scale=(0.5, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness = (0.6,1.4), hue = (-0.5,0.5), saturation = (0.6,1.4)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "  ]))\n",
    "\n",
    "val_dataset = CelebA(\n",
    "  '',\n",
    "  'val_40_att_list.txt',\n",
    "  'Img',\n",
    "  transforms.Compose([\n",
    "    transforms.CenterCrop(178),\n",
    "    transforms.Resize(crop_size),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "  ]))\n",
    "\n",
    "test_dataset = CelebA(\n",
    "  '',\n",
    "  'test_40_att_list.txt',\n",
    "  'Img',\n",
    "  transforms.Compose([\n",
    "    transforms.CenterCrop(178),\n",
    "    transforms.Resize(crop_size),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "  ]))\n",
    "\n",
    "eval_dataset = LFWA(\n",
    "  '',\n",
    "  'testset.txt',\n",
    "  'testset',\n",
    "  transforms.Compose([\n",
    "    transforms.CenterCrop(178),\n",
    "    transforms.Resize(crop_size),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "  ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  train_dataset, batch_size = batch_size, shuffle = True,\n",
    "  num_workers = num_workers, pin_memory=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "  val_dataset,\n",
    "  batch_size = test_batch, shuffle = False,\n",
    "  num_workers = num_workers, pin_memory = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  test_dataset,\n",
    "  batch_size = test_batch, shuffle = False,\n",
    "  num_workers = num_workers, pin_memory = True)\n",
    "\n",
    "eval_loader = torch.utils.data.DataLoader(\n",
    "  eval_dataset,\n",
    "  batch_size = test_batch, shuffle = False,\n",
    "  num_workers = num_workers, pin_memory = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-Trained ResNeSt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('zhanghang1989/ResNeSt', arch, pretrained = True)\n",
    "model.fc = Classifier(model.fc.in_features, 40)\n",
    "model.cuda()\n",
    "criterion = FocalLoss(alpha, gamma).cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr,\n",
    "                                momentum = momentum,\n",
    "                                weight_decay = weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load States (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint['model'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "  train_loss, train_acc = train(train_loader, model, criterion, optimizer)\n",
    "  val_loss, val_acc = validate(val_loader, model, criterion)\n",
    "  scheduler.step(val_loss)\n",
    "  torch.save({\n",
    "  'arch': arch,\n",
    "  'batch_size': batch_size,\n",
    "  'crop_size': crop_size,\n",
    "  'train_loss': train_loss,\n",
    "  'train_acc': train_acc,\n",
    "  'val_loss': val_loss,\n",
    "  'val_acc': val_acc,\n",
    "  'model': model.state_dict(),\n",
    "  'optimizer': optimizer.state_dict(),\n",
    "  'scheduler': scheduler.state_dict(),\n",
    "  'alpha': alpha,\n",
    "  'gamma': gamma\n",
    "}, arch + '.checkpoint' + str(scheduler.state_dict()['last_epoch']) + '.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = validate(test_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict(eval_loader, model, eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc. Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in model.children():\n",
    "  for param in child.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.fc.parameters():\n",
    "  param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint = None\n",
    "for i in range(1,20+1):\n",
    "  checkpoint = torch.load('resnest50.checkpoint' + str(i) + '.pth.tar')\n",
    "  display(i)\n",
    "  display('Train Loss: ' + str(checkpoint['train_loss']))\n",
    "  display('Train Acc: ' + str(checkpoint['train_acc']))\n",
    "  display('Val Loss: ' + str(checkpoint['val_loss']))\n",
    "  display('Val Acc: ' + str(checkpoint['val_acc']))\n",
    "  display('Margin: ' + str(abs(checkpoint['train_acc']-checkpoint['val_acc'])))\n",
    "  if last_checkpoint != None:\n",
    "    display('Val Acc Delta: ' + str(checkpoint['val_acc']-last_checkpoint['val_acc']))\n",
    "  print('')\n",
    "  last_checkpoint = checkpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
